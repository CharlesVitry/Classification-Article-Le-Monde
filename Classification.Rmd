---
title: |
  ![](RStudio_Logo.png){width=125%}  
  Classification des articles du monde en fonction de leur contenu
author: 
- Charles Vitry
- Clovis Deletre
date: "[Fichiers de données et de test fournis](https://www.lemonde.fr/)"
output:
  rmarkdown::html_document:
    theme: cerulean
    number_sections: no
    toc: yes
    toc_depth: 5
    toc_float: true
---
<style type="text/css">

body{ /* Normal  */
      font-size: 12px;
  }
td {  /* Table  */
  font-size: 8px;
}
h1.title {
  font-size: 38px;
  color: DarkBlue;
}
h1 { /* Header 1 */
  font-size: 28px;
  color: DarkBlue;
}
h2 { /* Header 2 */
    font-size: 18px;
  color: DarkBlue;
}
h3 { /* Header 3 */
  font-size: 15px;
  font-family: "Times New Roman", Times, serif;
  color: DarkBlue;
}
code.r{ /* Code block */
    font-size: 12px;
}
pre { /* Code block - determines code spacing between lines */
    font-size: 14px;
}
</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)



#install for export in pdf file
#tinytex::install_tinytex()

if(!require(tm)) install.packages("tm", repos = "http://cran.us.r-project.org")
require(tm)

if(!require(wordcloud2)) install.packages("wordcloud2", repos = "http://cran.us.r-project.org")
require(wordcloud2)

if(!require(randomForest)) install.packages("randomForest", repos = "http://cran.us.r-project.org")
require(randomForest)

if(!require(SnowballC)) install.packages("SnowballC", repos = "http://cran.us.r-project.org")
require(SnowballC)


if(!require(sparkline)) install.packages("sparkline", repos = "http://cran.us.r-project.org")
require(sparkline)


# Construction de l'arbre
if(!require(rpart)) install.packages("rpart", repos = "http://cran.us.r-project.org")
require(rpart)

# Visualisation de l'arbre

if(!require(visNetwork)) install.packages("visNetwork", repos = "http://cran.us.r-project.org")
require(visNetwork)


# Evaluation des modèles 

if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
require(caret)
 
#Import required library
library(caret)


if(!require(ROCR)) install.packages("ROCR", repos = "http://cran.us.r-project.org")
require(ROCR)

```



## Import de la base de données & du jeu test

On utilise l'encodage UTF-8 car le monde est un journal français utilisant des caractères spéciaux.
```{r}
data <- 
   read.csv("le_monde.csv", encoding="UTF-8", sep=";", comment.char="#")

test <- 
  read.csv("lignes_jeux_tests.csv")

```

## transformation des données
Pour l’exercice l’élément positif est le fait d’être un article de type économie

Suppression des deux collones non utiles à la modélisation
```{r}
data$date <- NULL
data$title <- NULL
```

Supprimer les lignes avec des valeurs manquantes (normalement aucune supprimmé)
```{r , echo=FALSE}
which(is.na(data))
data <- na.omit(data)
```
on applique les bons types de variables
```{r}
data$category <- as.factor(data$category)
data$content <- as.character(data$content)
str(data)
```


On retire les accents
```{r, echo=TRUE}
Encoding(data$content)
data$content <- iconv(data$content,from="UTF-8",to="ASCII//TRANSLIT")

```
On a besoin d'un objet de type corpus, 
on prend là ou sont les données, ici la collone V6.
On affiche la première ligne
```{r}
contenu <- Corpus(VectorSource(data$content))
contenu[1]$content

```



On supprime les caracteres qui ne sont pas des lettres,
```{r}
contenu <- tm_map(contenu, content_transformer(gsub), pattern = "[^a-zA-Z]", replacement = " ")
                 
contenu[1]$content


```
On mets les majuscules en minuscules
```{r}
contenu <- tm_map(contenu, content_transformer(tolower))
contenu[1]$content

```


On retire les lettres isolés et les mots "vides" tel "quand, comme, hors ..."
```{r}
stopwords_fr <- stopwords("french")
stopwords_fr <- c(stopwords_fr, "a","b","c","d","e","f","g","h","i","j","k","l","m","n","o","p","q","r","s","t",
                   "u","v","w","x","y","z" )

contenu <- tm_map(contenu, removeWords , stopwords_fr)
contenu[1]$content

```
Racinisation (sans retirer le premier espace)
```{r}
contenu <- tm_map(contenu, stemDocument, "french")
contenu[1]$content

contenu <- tm_map(contenu , stripWhitespace)
contenu <- tm_map(contenu, content_transformer(gsub), pattern = "^\\s+", replacement = "")
contenu[1]$content



```

Vectorisation
1000 occurences minimum
```{r, warning=FALSE,echo=TRUE}
dtm <- DocumentTermMatrix(contenu)

minfreq <- findFreqTerms(dtm , 1000) 

dtm <- DocumentTermMatrix(contenu, control=list(dictionary = minfreq, weighting= weightTf)) 

base_modele <- data.frame(as.matrix(dtm))

head(base_modele[1,1:5])

```

```{r}

```


Le traitement de text effectué, on re-ajoute les données au tableau en gardant les colonnes qu'on a besoin :
```{r, echo= TRUE}
data$content_modif = data.frame(text = sapply(contenu$content, as.character), stringsAsFactors = FALSE)[,1]



mots <-paste(data[data$category =="1", "content_modif"], collapse = "")
print <- substr(mots, start=1, stop=100)
motsFreq <- data.frame(sort(table(strsplit(mots,"\\s+")),decreasing=TRUE)) 
head(motsFreq)
#wordcloud2(data = motsFreq[1:500,],minSize = 5, size = 3)




base_modelisation = cbind.data.frame(data, base_modele)
base_modelisation = base_modelisation[,-2]
base_modelisation = base_modelisation[,-2]
#base_modelisation

```




```{r}

```

```{r}

```


# Présentation des données

Variables à expliquer : culture, economie, planete, politique, societe, sport.

439 Variables explicatives : les mots qui apparaissent plus de 1000 fois.

Nous n'effectuons que la dernière partie d'un projet de Data Science : la modélisation,
cette étape constitue 5 à 20% du temps consacré à un ce type de projet.

corrélations
```{r}

```

distribution
```{r}
#summary(base_modelisation)
```



#Modèle Supervisé
Apprentissage supervisé: expliquer/prédire  une sortie Y à partir d’entrées X 
Nous devons éviter le sur-apprentissage.

Modèle supervisé pouvant être utilisé : CART , randomforest, régression linéaire


On commence par construire un modèle d'apprentissage, composé de 80% des lignes de base_modelisation.

```{r}
nb_lignes <- sample(1:nrow(base_modelisation), nrow(base_modelisation)*0.80)
```


## Premier modèle
Modélisation : Arbre, algorithme : CART


Le principe est que, tant qu'on a pas atteind la taille minimal de noeuds enfants on recherche un seuil qui permet de séparer le noeud parents en 2 noeuds enfants en maximisant le gain d'impureté*

Gain d'impureté : trouver une def + simple 

```{r}
tree <-rpart(category~. , data = base_modelisation[nb_lignes,], cp=0, minsplit = 10)

visTree(tree)
```

On recherche le cp adapté (à revoir)

```{r}



```

Evaluation, matrice de confusion :
```{r}
p <- predict(tree, newdata=base_modelisation[-nb_lignes,], type= "class")
length(p)

conf <- confusionMatrix(data=p, reference = base_modelisation[-nb_lignes,]$category)
conf

```
AUC

```{r}
library(ROCR)
library(pROC)

p1 <- predict(tree, newdata=base_modelisation[-nb_lignes,], type= "prob")
p1 <- p1[,1]


length(base_modelisation[-nb_lignes,]$category)

auc(base_modelisation[-nb_lignes,]$category, p1)
```





## Deuxième modèle
Modélisation : Random Forest, algorithme de bagging 


Le principe est de créer n arbres non corrélés entre eux puis faire voter chacun d'entre eux.

Pour faire varier un arbre on sélectionne une partie différente des données à chaque noeud et ne construisant des arbres que sur une partie des individus

Ici :
- mtry : 20
- nbtree: 500
- 

```{r}

#modele_rf <- randomForest(x=base_modelisation[nb_lignes,-58], y = base_modelisation[nb_lignes,58], ntree=100)
#print(modele_rf)


modele_rf = randomForest(category~. , data=base_modelisation[nb_lignes,], importance = T, ntree = 100)
modele_rf
plot(modele_rf)

```

AUC
```{r}
p1 <- predict(modele_rf, newdata=base_modelisation[-nb_lignes,], type= "prob")
p1 <- p1[,1]


length(base_modelisation[-nb_lignes,]$category)

auc(base_modelisation[-nb_lignes,]$category, p1)


```


## Troisième modèle
```{r}

```

## Comparaison modèle
```{r}

```
```{r}

```
```{r}

```

## Mise en œuvre d’un modèle supervisé avec maximum 25 variables
```{r}

```

```{r}

```

```{r}

```

```{r}

```



